{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 620 Project 3\n",
    "\n",
    "Farhana Zahir, Benjamin Horvath, Luisa Velasco, Corey Arnouts, Shovan Biswas, Jimmy Ng, \n",
    "Randy Thompson, Sam Cohen-Devries, Joby John\n",
    "\n",
    "Youtube: https://youtu.be/Y-Sux3xq5G8\n",
    "\n",
    "**Description**\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can.\n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "Source: Natural Lnaguage Processing with Python, exercise 6.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages required\n",
    "import collections\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.classify import apply_features\n",
    "from nltk.corpus import names\n",
    "from nltk.metrics import ConfusionMatrix, accuracy, precision, recall, f_measure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**\n",
    "\n",
    "The `names` dataset is built into the `nltk` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names.zip/names/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-feb5a4faae0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check the corpus, there are two files, female.txt and male.txt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# check the corpus, there are two files, female.txt and male.txt\n",
    "names = nltk.corpus.names\n",
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names.zip/names/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-de90dddf89e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'female.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'male.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "len(names.words('female.txt')), len(names.words('male.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are nearly twice as many female names as male in this data set.\n",
    "\n",
    "Comparing the frequency distributions of beginning letters by gender, we see that more female names start with the first letters A, C, M and S. \n",
    "\n",
    "The last names do follow what is set in the textbook, names ending in A, E and I tend to be female. However, names ending in L, N and S tend to be male here, whereas the textbook in section 2.4 finds that names ending in K, O, R, S and T tend to be male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names.zip/names/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c05acdf80920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check distribution for first letter of name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m gender_freq = nltk.ConditionalFreqDist((fileid, name[0])\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     for name in names.words(fileid))\n\u001b[0;32m      5\u001b[0m \u001b[0mgender_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Check distribution for first letter of name\n",
    "gender_freq = nltk.ConditionalFreqDist((fileid, name[0])\n",
    "    for fileid in names.fileids()\n",
    "    for name in names.words(fileid))\n",
    "gender_freq.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same exercise can be applied to the last letter of names. Overwhelmingly, names that end in A, E, and I are female. Although it's hard to see from this representation, it appears that names that end N and Y may be more likely to be male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names.zip/names/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-986da1dad7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check distribution for last letter of name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m gender_freq = nltk.ConditionalFreqDist((fileid, name[-1])\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     for name in names.words(fileid))\n\u001b[0;32m      5\u001b[0m \u001b[0mgender_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mnames\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('names')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/names\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Check distribution for last letter of name\n",
    "gender_freq = nltk.ConditionalFreqDist((fileid, name[-1])\n",
    "    for fileid in names.fileids()\n",
    "    for name in names.words(fileid))\n",
    "gender_freq.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning and Exploration**\n",
    "\n",
    "We will first merge the two text files and shuffle them. Then we divide as follows:\n",
    "\n",
    "__Development set:__\n",
    "\n",
    "6214 names for the training (train_names)\n",
    "500 names for the testing (devtest_names)\n",
    "\n",
    "__Test set:__\n",
    "\n",
    "500 names for the testing (test_names)\n",
    "The training set is used to train the model, and the dev-test set is used to perform error analysis. The test set serves in our final evaluation of the model.\n",
    "\n",
    "Models are trained on the training set and then the development set is used to evaluate it for further modification. The final evaluation is on the test set, which was not used for model training at all, and thus model performance on the test set can be taken as a close estimate of the model's performance in reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Antonetta', 'female'),\n",
       " ('Roana', 'female'),\n",
       " ('Tarrah', 'female'),\n",
       " ('Leoine', 'female'),\n",
       " ('Rab', 'male'),\n",
       " ('Waldo', 'male'),\n",
       " ('Nelia', 'female'),\n",
       " ('Ardra', 'female'),\n",
       " ('Jud', 'male')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two text files and shuffle\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + \n",
    "        [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.seed(1804)\n",
    "random.shuffle(names)\n",
    "names[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7579"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see number of unique names\n",
    "len(set(item[0] for item in names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue we have to deal with is that some names are listed as both male and female. They are removed entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cat', 2),\n",
       " ('Carlin', 2),\n",
       " ('Freddy', 2),\n",
       " ('Tommy', 2),\n",
       " ('Kerry', 2),\n",
       " ('Tommie', 2),\n",
       " ('Christian', 2),\n",
       " ('Jerrie', 2),\n",
       " ('Allie', 2),\n",
       " ('Chris', 2),\n",
       " ('Meryl', 2),\n",
       " ('Blair', 2),\n",
       " ('Mel', 2),\n",
       " ('Mickie', 2),\n",
       " ('Rey', 2),\n",
       " ('Georgie', 2),\n",
       " ('Abbey', 2),\n",
       " ('Francis', 2),\n",
       " ('Valentine', 2),\n",
       " ('Haley', 2),\n",
       " ('Jordan', 2),\n",
       " ('Addie', 2),\n",
       " ('Felice', 2),\n",
       " ('Deane', 2),\n",
       " ('Tammie', 2),\n",
       " ('Bo', 2),\n",
       " ('Virgie', 2),\n",
       " ('Dory', 2),\n",
       " ('Tally', 2),\n",
       " ('Carmine', 2),\n",
       " ('Vin', 2),\n",
       " ('Donny', 2),\n",
       " ('Constantine', 2),\n",
       " ('Averil', 2),\n",
       " ('Marty', 2),\n",
       " ('Christie', 2),\n",
       " ('Dell', 2),\n",
       " ('Val', 2),\n",
       " ('Brett', 2),\n",
       " ('Ira', 2),\n",
       " ('Kelsey', 2),\n",
       " ('Tobie', 2),\n",
       " ('Dionis', 2),\n",
       " ('Andy', 2),\n",
       " ('Fran', 2),\n",
       " ('Lin', 2),\n",
       " ('Ronnie', 2),\n",
       " ('Evelyn', 2),\n",
       " ('Jody', 2),\n",
       " ('Chad', 2),\n",
       " ('Theo', 2),\n",
       " ('Michele', 2),\n",
       " ('Tate', 2),\n",
       " ('Wynn', 2),\n",
       " ('Jodie', 2),\n",
       " ('Ollie', 2),\n",
       " ('Matty', 2),\n",
       " ('Pooh', 2),\n",
       " ('Meade', 2),\n",
       " ('Patrice', 2),\n",
       " ('Joey', 2),\n",
       " ('Glenn', 2),\n",
       " ('Fred', 2),\n",
       " ('Sayre', 2),\n",
       " ('Alix', 2),\n",
       " ('Lesley', 2),\n",
       " ('Paige', 2),\n",
       " ('Clemmie', 2),\n",
       " ('Whitney', 2),\n",
       " ('Pat', 2),\n",
       " ('Kit', 2),\n",
       " ('Bert', 2),\n",
       " ('Darryl', 2),\n",
       " ('Sean', 2),\n",
       " ('Germaine', 2),\n",
       " ('Lindsay', 2),\n",
       " ('Shay', 2),\n",
       " ('Bobbie', 2),\n",
       " ('Haleigh', 2),\n",
       " ('Willie', 2),\n",
       " ('Billie', 2),\n",
       " ('Jo', 2),\n",
       " ('Henrie', 2),\n",
       " ('Alex', 2),\n",
       " ('Lou', 2),\n",
       " ('Merrill', 2),\n",
       " ('Gerry', 2),\n",
       " ('Barry', 2),\n",
       " ('Judy', 2),\n",
       " ('Ikey', 2),\n",
       " ('Julie', 2),\n",
       " ('Jodi', 2),\n",
       " ('Lyn', 2),\n",
       " ('Georgia', 2),\n",
       " ('Danny', 2),\n",
       " ('Lanny', 2),\n",
       " ('Jan', 2),\n",
       " ('Brook', 2),\n",
       " ('Loren', 2),\n",
       " ('Del', 2),\n",
       " ('Judith', 2),\n",
       " ('Geri', 2),\n",
       " ('Carroll', 2),\n",
       " ('Regan', 2),\n",
       " ('Heath', 2),\n",
       " ('Adrien', 2),\n",
       " ('Millicent', 2),\n",
       " ('Carey', 2),\n",
       " ('Justin', 2),\n",
       " ('Dannie', 2),\n",
       " ('Stacy', 2),\n",
       " ('Shell', 2),\n",
       " ('Pattie', 2),\n",
       " ('Devin', 2),\n",
       " ('Leslie', 2),\n",
       " ('Terry', 2),\n",
       " ('Lynn', 2),\n",
       " ('Marion', 2),\n",
       " ('Kellen', 2),\n",
       " ('Wallie', 2),\n",
       " ('Terri', 2),\n",
       " ('Winny', 2),\n",
       " ('Randi', 2),\n",
       " ('Eddy', 2),\n",
       " ('Cam', 2),\n",
       " ('Cory', 2),\n",
       " ('Rory', 2),\n",
       " ('Michel', 2),\n",
       " ('Corrie', 2),\n",
       " ('Billy', 2),\n",
       " ('Austin', 2),\n",
       " ('Jerry', 2),\n",
       " ('Juanita', 2),\n",
       " ('Winnie', 2),\n",
       " ('Marlo', 2),\n",
       " ('Sonnie', 2),\n",
       " ('Vinnie', 2),\n",
       " ('Adrian', 2),\n",
       " ('Alexis', 2),\n",
       " ('Cris', 2),\n",
       " ('Tony', 2),\n",
       " ('Lee', 2),\n",
       " ('Kelly', 2),\n",
       " ('Tammy', 2),\n",
       " ('Corey', 2),\n",
       " ('Page', 2),\n",
       " ('Shayne', 2),\n",
       " ('Harley', 2),\n",
       " ('Abbie', 2),\n",
       " ('Donnie', 2),\n",
       " ('Franky', 2),\n",
       " ('Tracey', 2),\n",
       " ('Daffy', 2),\n",
       " ('Edie', 2),\n",
       " ('Ray', 2),\n",
       " ('Merle', 2),\n",
       " ('Kyle', 2),\n",
       " ('Trace', 2),\n",
       " ('Leland', 2),\n",
       " ('Wallis', 2),\n",
       " ('Saundra', 2),\n",
       " ('Ike', 2),\n",
       " ('Allyn', 2),\n",
       " ('Willy', 2),\n",
       " ('Gill', 2),\n",
       " ('Kirby', 2),\n",
       " ('Sammy', 2),\n",
       " ('Tim', 2),\n",
       " ('Emmy', 2),\n",
       " ('Sal', 2),\n",
       " ('Bertie', 2),\n",
       " ('Hannibal', 2),\n",
       " ('Denny', 2),\n",
       " ('Ali', 2),\n",
       " ('Muffin', 2),\n",
       " ('Holly', 2),\n",
       " ('Angie', 2),\n",
       " ('Jaime', 2),\n",
       " ('Sydney', 2),\n",
       " ('Gus', 2),\n",
       " ('Scotty', 2),\n",
       " ('Aubrey', 2),\n",
       " ('Ted', 2),\n",
       " ('Esme', 2),\n",
       " ('Penny', 2),\n",
       " ('Jean', 2),\n",
       " ('Dominique', 2),\n",
       " ('Karel', 2),\n",
       " ('Cody', 2),\n",
       " ('Ariel', 2),\n",
       " ('Connie', 2),\n",
       " ('Vale', 2),\n",
       " ('Sibyl', 2),\n",
       " ('Simone', 2),\n",
       " ('Reggie', 2),\n",
       " ('Phil', 2),\n",
       " ('Lane', 2),\n",
       " ('Nickie', 2),\n",
       " ('Bennie', 2),\n",
       " ('Andrea', 2),\n",
       " ('Demetris', 2),\n",
       " ('Maddy', 2),\n",
       " ('Quentin', 2),\n",
       " ('Sonny', 2),\n",
       " ('Gayle', 2),\n",
       " ('Freddie', 2),\n",
       " ('Claude', 2),\n",
       " ('Wally', 2),\n",
       " ('Kim', 2),\n",
       " ('Dani', 2),\n",
       " ('Lorrie', 2),\n",
       " ('Lauren', 2),\n",
       " ('Clem', 2),\n",
       " ('Claire', 2),\n",
       " ('Dallas', 2),\n",
       " ('Bernie', 2),\n",
       " ('Mead', 2),\n",
       " ('Kris', 2),\n",
       " ('Maxie', 2),\n",
       " ('Meredith', 2),\n",
       " ('Daniel', 2),\n",
       " ('Courtney', 2),\n",
       " ('Andie', 2),\n",
       " ('Tabby', 2),\n",
       " ('Tallie', 2),\n",
       " ('Cammy', 2),\n",
       " ('Hilary', 2),\n",
       " ('Gale', 2),\n",
       " ('Teddy', 2),\n",
       " ('Abby', 2),\n",
       " ('Willi', 2),\n",
       " ('Vinny', 2),\n",
       " ('Mattie', 2),\n",
       " ('Ajay', 2),\n",
       " ('Van', 2),\n",
       " ('Lindy', 2),\n",
       " ('Cecil', 2),\n",
       " ('Grace', 2),\n",
       " ('Blake', 2),\n",
       " ('Gay', 2),\n",
       " ('Merry', 2),\n",
       " ('Leigh', 2),\n",
       " ('Martie', 2),\n",
       " ('Ricky', 2),\n",
       " ('Barrie', 2),\n",
       " ('Timmy', 2),\n",
       " ('Angel', 2),\n",
       " ('Ginger', 2),\n",
       " ('Nat', 2),\n",
       " ('Hillary', 2),\n",
       " ('Isadore', 2),\n",
       " ('Gabriell', 2),\n",
       " ('Dorian', 2),\n",
       " ('Lindsey', 2),\n",
       " ('Max', 2),\n",
       " ('Hazel', 2),\n",
       " ('Dale', 2),\n",
       " ('Elisha', 2),\n",
       " ('Quinn', 2),\n",
       " ('Torey', 2),\n",
       " ('Dana', 2),\n",
       " ('Maurise', 2),\n",
       " ('Gerri', 2),\n",
       " ('Kelley', 2),\n",
       " ('Darcy', 2),\n",
       " ('Chrissy', 2),\n",
       " ('Teddie', 2),\n",
       " ('Nichole', 2),\n",
       " ('Morlee', 2),\n",
       " ('Dennie', 2),\n",
       " ('Carlie', 2),\n",
       " ('Brooke', 2),\n",
       " ('Darby', 2),\n",
       " ('Jackie', 2),\n",
       " ('Sasha', 2),\n",
       " ('Tobe', 2),\n",
       " ('Maddie', 2),\n",
       " ('Cass', 2),\n",
       " ('Eddie', 2),\n",
       " ('Ruby', 2),\n",
       " ('Luce', 2),\n",
       " ('Shannon', 2),\n",
       " ('Shaun', 2),\n",
       " ('Shelby', 2),\n",
       " ('Tabbie', 2),\n",
       " ('Casey', 2),\n",
       " ('Kip', 2),\n",
       " ('Jessie', 2),\n",
       " ('Clair', 2),\n",
       " ('Shelley', 2),\n",
       " ('Cal', 2),\n",
       " ('Ronny', 2),\n",
       " ('Benny', 2),\n",
       " ('Shea', 2),\n",
       " ('Drew', 2),\n",
       " ('Laurie', 2),\n",
       " ('Toby', 2),\n",
       " ('Shaine', 2),\n",
       " ('Isa', 2),\n",
       " ('Patty', 2),\n",
       " ('Dion', 2),\n",
       " ('Michal', 2),\n",
       " ('Ricki', 2),\n",
       " ('Brooks', 2),\n",
       " ('Gene', 2),\n",
       " ('Jamie', 2),\n",
       " ('Randy', 2),\n",
       " ('Christy', 2),\n",
       " ('Tracy', 2),\n",
       " ('Timmie', 2),\n",
       " ('Bobby', 2),\n",
       " ('Lonnie', 2),\n",
       " ('Niki', 2),\n",
       " ('Augustine', 2),\n",
       " ('Jesse', 2),\n",
       " ('Ashley', 2),\n",
       " ('Jermaine', 2),\n",
       " ('Isador', 2),\n",
       " ('Pennie', 2),\n",
       " ('Alfie', 2),\n",
       " ('Brandy', 2),\n",
       " ('Clare', 2),\n",
       " ('Nikki', 2),\n",
       " ('Sam', 2),\n",
       " ('Glen', 2),\n",
       " ('Gabriel', 2),\n",
       " ('Randie', 2),\n",
       " ('Lorne', 2),\n",
       " ('George', 2),\n",
       " ('Beau', 2),\n",
       " ('Devon', 2),\n",
       " ('Jess', 2),\n",
       " ('Bryn', 2),\n",
       " ('Perry', 2),\n",
       " ('Patsy', 2),\n",
       " ('Pen', 2),\n",
       " ('Erin', 2),\n",
       " ('Sunny', 2),\n",
       " ('Sandy', 2),\n",
       " ('Frank', 2),\n",
       " ('Cary', 2),\n",
       " ('Daryl', 2),\n",
       " ('Shawn', 2),\n",
       " ('Shane', 2),\n",
       " ('Robin', 2),\n",
       " ('Noel', 2),\n",
       " ('Robbie', 2),\n",
       " ('Gail', 2),\n",
       " ('Micky', 2),\n",
       " ('Rikki', 2),\n",
       " ('Nicky', 2),\n",
       " ('Bill', 2),\n",
       " ('Frankie', 2),\n",
       " ('Morgan', 2),\n",
       " ('Caryl', 2),\n",
       " ('Lind', 2),\n",
       " ('Rene', 2),\n",
       " ('Rickie', 2),\n",
       " ('Britt', 2),\n",
       " ('Jude', 2),\n",
       " ('Jere', 2),\n",
       " ('Tracie', 2),\n",
       " ('Marietta', 2),\n",
       " ('Sascha', 2),\n",
       " ('Gretchen', 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate name distribution and show names that are not unique\n",
    "names_only = [item[0] for item in names]\n",
    "names_dist = nltk.FreqDist(names_only)\n",
    "names_dupes = [(k,v) for k,v in names_dist.items() if v >1]\n",
    "names_dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Abbie', 'female'),\n",
       " ('Franky', 'female'),\n",
       " ('Quentin', 'male'),\n",
       " ('Abbie', 'male'),\n",
       " ('Franky', 'male'),\n",
       " ('Quentin', 'female')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at sample duplicates\n",
    "[item for item in names if item[0] in [\"Franky\",\"Quentin\",\"Abbie\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the duplicates and show total number of unique names\n",
    "names2remove = [item[0] for item in names_dupes]\n",
    "final_names = [item for item in names if not item[0] in names2remove]\n",
    "len(final_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, split the data set, and examine the gender imbalance in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set = 6214\n",
      "Dev-Test Set = 500\n",
      "Test Set = 500\n"
     ]
    }
   ],
   "source": [
    "test = final_names[0:500]\n",
    "devtest = final_names[500:1000]\n",
    "train = final_names[1000:]\n",
    "\n",
    "# Confirm the size of the three subsets\n",
    "print(\"Training Set = {}\".format(len(train)))\n",
    "print(\"Dev-Test Set = {}\".format(len(devtest)))\n",
    "print(\"Test Set = {}\".format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'female': 3997, 'male': 2217})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#C heck the distribution of females vs males in the train dataset\n",
    "train_dist = [g  for (n, g) in train]\n",
    "nltk.FreqDist(train_dist)\n",
    "\n",
    "#As expected there are a lot more female names than male names in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification using Naive Bayes**\n",
    "\n",
    "We subject SEVEN different feature sets to a Naive Bayes classifier. The classifier uses the feature set to predict whether a name is female or male. We study the predictive power of the first and last letters of a name, the last letter, the last two letters, a series of bi- and trigrams made up of names, and finally counts of syllables.\n",
    "\n",
    "Because of the gender imbalance in the data set, accuracy may provide a skewed evaluation. In addition to accuracy, recall and precision are reported for each class via a custom function.\n",
    "\n",
    "* Precision -- Signifying false positives, i.e., improved precision indicates fewer false positives.\n",
    "\n",
    "* Recall -- Measures false negatives, i.e., improved recall indicates fewer false negatives.\n",
    "\n",
    "Naturally these two measures are often at odds with eachother.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(model, train, digits=4):\n",
    "    \"\"\"Prints the precision and recall of an NLTK Naive Bayes model.\"\"\"\n",
    "    reference = collections.defaultdict(set)\n",
    "    test = collections.defaultdict(set)\n",
    "    \n",
    "    for i, (features, label) in enumerate(train):\n",
    "        reference[label].add(i)\n",
    "        pred = model.classify(features)\n",
    "        test[pred].add(i)\n",
    "        \n",
    "    m_precision = round(precision(reference['male'], test['male']), digits)\n",
    "    f_precision = round(precision(reference['female'], test['female']), digits)\n",
    "    \n",
    "    m_recall = round(recall(reference['male'], test['male']), digits)\n",
    "    f_recall = round( recall(reference['female'], test['female']), digits)\n",
    "        \n",
    "    print('Male precision: ', m_precision)\n",
    "    print('Female precision: ', f_precision)\n",
    "    print('Male recall: ', m_recall)\n",
    "    print('Female recall: ', f_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 1: First vs Last Letter**\n",
    "\n",
    "We will test whether using first letter or last letter gives us a better  results. We fidn that using the last letter improves performance of both the datasets.\n",
    "\n",
    "First, develop a function to extract the first letter of a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_1_letter': 'm'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature 1 first letter\n",
    "def first_letter(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'first_1_letter': name[0]\n",
    "        }\n",
    "first_letter(\"Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devset accuracy is\n",
      "0.662\n",
      "Test accuracy is\n",
      "0.648\n"
     ]
    }
   ],
   "source": [
    "train_set = [(first_letter(n), g) for (n,g) in train]\n",
    "devtest_set = [(first_letter(n), g) for (n,g) in devtest]\n",
    "test_set = [(first_letter(n), g) for (n,g) in test]\n",
    "nb1 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "\n",
    "print('Devset accuracy is')\n",
    "print(nltk.classify.accuracy(nb1, devtest_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb1, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.6532\n",
      "Female precision:  0.666\n",
      "Male recall:  0.1308\n",
      "Female recall:  0.9615\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb1, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.6389\n",
      "Female precision:  0.6638\n",
      "Male recall:  0.1285\n",
      "Female recall:  0.9595\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb1, devtest_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much difference between the train and development sets, indicating it is unlikely the model is overfitting the data.\n",
    "\n",
    "What is most striking is how many false negatives the model performs on male names. The model is biased toward females names, over-classifying male names as female. Because of this, the model has a great recall on female names of nearly 1.0.\n",
    "\n",
    "The model determines the most informative feature is beginning with a W, much more likely to be male than female. Q, K, U, H, and X are also fairly informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          first_1_letter = 'w'              male : female =      6.2 : 1.0\n",
      "          first_1_letter = 'q'              male : female =      3.8 : 1.0\n",
      "          first_1_letter = 'k'            female : male   =      2.5 : 1.0\n",
      "          first_1_letter = 'u'              male : female =      2.5 : 1.0\n",
      "          first_1_letter = 'h'              male : female =      2.4 : 1.0\n",
      "          first_1_letter = 'x'              male : female =      2.2 : 1.0\n",
      "          first_1_letter = 'l'            female : male   =      1.9 : 1.0\n",
      "          first_1_letter = 'c'            female : male   =      1.9 : 1.0\n",
      "          first_1_letter = 'z'              male : female =      1.7 : 1.0\n",
      "          first_1_letter = 'y'              male : female =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Looking at the most informative features\n",
    "nb1.show_most_informative_features(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 2: Last Letter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_1_letter': 'y'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature 2 last letter\n",
    "def last_letter(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'last_1_letter': name[-1]\n",
    "        }\n",
    "last_letter(\"Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devset accuracy is\n",
      "0.778\n",
      "Test accuracy is\n",
      "0.786\n"
     ]
    }
   ],
   "source": [
    "train_set = [(last_letter(n), g) for (n,g) in train]\n",
    "devtest_set = [(last_letter(n), g) for (n,g) in devtest]\n",
    "test_set = [(last_letter(n), g) for (n,g) in test]\n",
    "nb2 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Devset accuracy is')\n",
    "print(nltk.classify.accuracy(nb2, devtest_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb2, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.7032\n",
      "Female precision:  0.8404\n",
      "Male recall:  0.7149\n",
      "Female recall:  0.8326\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb2, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.6735\n",
      "Female precision:  0.8454\n",
      "Male recall:  0.7374\n",
      "Female recall:  0.8006\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb2, devtest_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly slight overfitting, but hardly a worrying amount. Recall and precision for both classes are vastly superior to the first model. By itself, it appears the last letter is an excellent feature for the present purpose.\n",
    "\n",
    "Examining the most informative features, we can see the top odds are much greater than before. A name that starts with K is over 73 times more likely to be male than female! Even the tenth ratio is 6.1 : 1.0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           last_1_letter = 'k'              male : female =     71.3 : 1.0\n",
      "           last_1_letter = 'a'            female : male   =     51.8 : 1.0\n",
      "           last_1_letter = 'm'              male : female =     18.8 : 1.0\n",
      "           last_1_letter = 'p'              male : female =     16.2 : 1.0\n",
      "           last_1_letter = 'v'              male : female =     16.2 : 1.0\n",
      "           last_1_letter = 'f'              male : female =     14.7 : 1.0\n",
      "           last_1_letter = 'd'              male : female =     11.2 : 1.0\n",
      "           last_1_letter = 'o'              male : female =     10.3 : 1.0\n",
      "           last_1_letter = 'r'              male : female =      7.9 : 1.0\n",
      "           last_1_letter = 'z'              male : female =      6.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Looking at the most informative features\n",
    "nb2.show_most_informative_features(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 3: Last 2 letters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_2_letters': 'dy'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_2_letters(name):\n",
    "    name = name.lower()\n",
    "    return {\n",
    "        'last_2_letters': name[-2:]\n",
    "        }\n",
    "last_2_letters(\"Andy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devset accuracy is\n",
      "0.812\n",
      "Test accuracy is\n",
      "0.818\n"
     ]
    }
   ],
   "source": [
    "train_set = [(last_2_letters(n), g) for (n,g) in train]\n",
    "devtest_set = [(last_2_letters(n), g) for (n,g) in devtest]\n",
    "test_set = [(last_2_letters(n), g) for (n,g) in test]\n",
    "nb3 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Devset accuracy is')\n",
    "print(nltk.classify.accuracy(nb3, devtest_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb3, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.815\n",
      "Female precision:  0.8414\n",
      "Male recall:  0.6897\n",
      "Female recall:  0.9132\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb3, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.7815\n",
      "Female precision:  0.8252\n",
      "Male recall:  0.6592\n",
      "Female recall:  0.8972\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb3, devtest_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight overfitting, but this model is performing superior to the previous two. The ratio of the most informative features continue to grow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          last_2_letters = 'na'           female : male   =    145.0 : 1.0\n",
      "          last_2_letters = 'la'           female : male   =     69.5 : 1.0\n",
      "          last_2_letters = 'ia'           female : male   =     49.7 : 1.0\n",
      "          last_2_letters = 'ta'           female : male   =     38.1 : 1.0\n",
      "          last_2_letters = 'us'             male : female =     34.1 : 1.0\n",
      "          last_2_letters = 'rt'             male : female =     32.0 : 1.0\n",
      "          last_2_letters = 'io'             male : female =     26.4 : 1.0\n",
      "          last_2_letters = 'do'             male : female =     24.0 : 1.0\n",
      "          last_2_letters = 'rd'             male : female =     23.6 : 1.0\n",
      "          last_2_letters = 'ld'             male : female =     23.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Looking at the most informative features\n",
    "nb3.show_most_informative_features(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature 4: 2 letters as suffix + last trigram + first trigram + first fourgram**\n",
    "\n",
    "Multiple features are subject to the NB classifier: A name's last letter, last two letters, the last three letters, the first letters, and the first four letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'e',\n",
       " 'suffix2': 'le',\n",
       " 'last_trigram': 'lle',\n",
       " 'first_trigram': 'mad',\n",
       " 'first_fourgram': 'made'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature4(name):\n",
    "        name = name.lower()\n",
    "        return {\n",
    "            'suffix1': name[-1:],\n",
    "            'suffix2': name[-2:],\n",
    "            'last_trigram': name[-3:],\n",
    "            'first_trigram': name[:3], \n",
    "            'first_fourgram': name[:4]\n",
    "               }\n",
    "feature4(\"Mademoiselle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devset accuracy is\n",
      "0.904\n",
      "Test accuracy is\n",
      "0.894\n"
     ]
    }
   ],
   "source": [
    "train_set = [(feature4(n), g) for (n,g) in train]\n",
    "devtest_set = [(feature4(n), g) for (n,g) in devtest]\n",
    "test_set = [(feature4(n), g) for (n,g) in test]\n",
    "nb4 = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Devset accuracy is')\n",
    "print(nltk.classify.accuracy(nb4, devtest_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(nb4, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.9086\n",
      "Female precision:  0.9668\n",
      "Male recall:  0.9414\n",
      "Female recall:  0.9475\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb4, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.8359\n",
      "Female precision:  0.9475\n",
      "Male recall:  0.9106\n",
      "Female recall:  0.9003\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(nb4, devtest_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all four measures at or above 0.90, this model is classifying almost perfectly. However, the features encoding the last two letters are vastly more important than many of the additions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =    145.0 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     71.3 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     69.5 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     51.8 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     49.7 : 1.0\n",
      "                 suffix2 = 'ta'           female : male   =     38.1 : 1.0\n",
      "                 suffix2 = 'us'             male : female =     34.1 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     32.0 : 1.0\n",
      "                 suffix2 = 'io'             male : female =     26.4 : 1.0\n",
      "                 suffix2 = 'do'             male : female =     24.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Looking at the most informative features\n",
    "nb4.show_most_informative_features(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features 5, 6, 7: Syllable Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Feature Engineering Based off of this work: \n",
    "https://arxiv.org/pdf/1606.05467.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this feature generation instead of just looking the prescence and count of every character instead we opted to group characters by Kiki and Bouba characters which are groupings of letters based off the way they are pronounced.\n",
    "\n",
    "We found some interesting reading on Bouba vs Kiki as well\n",
    "https://en.wikipedia.org/wiki/Bouba/kiki_effect\n",
    "https://www.scientificamerican.com/article/bring-science-home-bouba-kiki-effect/\n",
    "\n",
    "In the feature engineering below we also brought in the syllable count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for syllable count\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith(\"e\"):\n",
    "        count -= 1\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suffix1': 'e',\n",
       " 'suffix2': 'le',\n",
       " 'last_trigram': 'lle',\n",
       " 'first_trigram': 'mad',\n",
       " 'first_fourgram': 'made',\n",
       " 'bouba_letters': 5,\n",
       " 'kiki_letters': 4,\n",
       " 'syllable_count': 4}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final function including kiki, bouba letters\n",
    "def get_features(name):\n",
    "        name=name.lower()\n",
    "        return {\n",
    "            'suffix1': name[-1:],\n",
    "            'suffix2': name[-2:],\n",
    "            'last_trigram': name[-3:],\n",
    "            'first_trigram': name[:3], \n",
    "            'first_fourgram': name[:4],\n",
    "            'bouba_letters': len([v for v in name if v in 'blmnuo']),\n",
    "            'kiki_letters':len([v for v in name if v in 'kptiezv']),\n",
    "            'syllable_count':syllable_count(name)\n",
    "            \n",
    "               }\n",
    "get_features(\"Mademoiselle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devset accuracy is\n",
      "0.908\n",
      "Test accuracy is\n",
      "0.892\n"
     ]
    }
   ],
   "source": [
    "train_set = [(get_features(n), g) for (n,g) in train]\n",
    "devtest_set = [(get_features(n), g) for (n,g) in devtest]\n",
    "test_set = [(get_features(n), g) for (n,g) in test]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print('Devset accuracy is')\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))\n",
    "print('Test accuracy is')\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.9054\n",
      "Female precision:  0.9665\n",
      "Male recall:  0.9409\n",
      "Female recall:  0.9455\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(classifier, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male precision:  0.8342\n",
      "Female precision:  0.9568\n",
      "Male recall:  0.9274\n",
      "Female recall:  0.8972\n"
     ]
    }
   ],
   "source": [
    "performance_metrics(classifier, devtest_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this model does not appear to perform any better compared to the previous model, despite the most sophisticated feature engineering. An examination of the most informative features indicates why: Bouba and Kiki letters and syllable count barely register in the top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =    145.0 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     71.3 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     69.5 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     51.8 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     49.7 : 1.0\n",
      "                 suffix2 = 'ta'           female : male   =     38.1 : 1.0\n",
      "                 suffix2 = 'us'             male : female =     34.1 : 1.0\n",
      "                 suffix2 = 'rt'             male : female =     32.0 : 1.0\n",
      "                 suffix2 = 'io'             male : female =     26.4 : 1.0\n",
      "                 suffix2 = 'do'             male : female =     24.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error analysis on devtest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate errors\n",
    "def generate_errors(classifier, dataset): \n",
    "    \n",
    "    errors = [] \n",
    "\n",
    "    for (name, tag) in dataset:\n",
    "        guess = classifier.classify(get_features(name)) \n",
    "        if guess != tag: \n",
    "            errors.append((tag, guess, name))\n",
    "            \n",
    "    return errors\n",
    "#Function to print error\n",
    "def show_errors(errors, n = None):\n",
    "   \n",
    "    if n is not None: errors = errors[:n]\n",
    "            \n",
    "    for (tag, guess, name) in sorted(errors): \n",
    "        print('correct=%-8s guess=%-8s name=%-30s' %(tag, guess, name))\n",
    "    print(len(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Bess                          \n",
      "correct=female   guess=male     name=Buffy                         \n",
      "correct=female   guess=male     name=Christan                      \n",
      "correct=female   guess=male     name=Clio                          \n",
      "correct=female   guess=male     name=Devan                         \n",
      "correct=female   guess=male     name=Doloritas                     \n",
      "correct=female   guess=male     name=Em                            \n",
      "correct=female   guess=male     name=Eran                          \n",
      "correct=female   guess=male     name=Ethel                         \n",
      "correct=female   guess=male     name=Farrand                       \n",
      "correct=female   guess=male     name=Frances                       \n",
      "correct=female   guess=male     name=Gates                         \n",
      "correct=female   guess=male     name=Germain                       \n",
      "correct=female   guess=male     name=Gillan                        \n",
      "correct=female   guess=male     name=Gusty                         \n",
      "correct=female   guess=male     name=Harmony                       \n",
      "correct=female   guess=male     name=Heather                       \n",
      "correct=female   guess=male     name=Hedvig                        \n",
      "correct=female   guess=male     name=Iris                          \n",
      "correct=female   guess=male     name=Joannes                       \n",
      "correct=female   guess=male     name=Karon                         \n",
      "correct=female   guess=male     name=Kevyn                         \n",
      "correct=female   guess=male     name=Kym                           \n",
      "correct=female   guess=male     name=Mair                          \n",
      "correct=female   guess=male     name=Margalo                       \n",
      "correct=female   guess=male     name=Milissent                     \n",
      "correct=female   guess=male     name=Murial                        \n",
      "correct=female   guess=male     name=Nil                           \n",
      "correct=female   guess=male     name=Pris                          \n",
      "correct=female   guess=male     name=Raven                         \n",
      "correct=female   guess=male     name=Scarlet                       \n",
      "correct=female   guess=male     name=Sheril                        \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Ari                           \n",
      "correct=male     guess=female   name=Augie                         \n",
      "correct=male     guess=female   name=Benedict                      \n",
      "correct=male     guess=female   name=Che                           \n",
      "correct=male     guess=female   name=Esteban                       \n",
      "correct=male     guess=female   name=Eugen                         \n",
      "correct=male     guess=female   name=Eugene                        \n",
      "correct=male     guess=female   name=Felipe                        \n",
      "correct=male     guess=female   name=Isidore                       \n",
      "correct=male     guess=female   name=Lorenzo                       \n",
      "correct=male     guess=female   name=Merlin                        \n",
      "correct=male     guess=female   name=Morrie                        \n",
      "correct=male     guess=female   name=Roni                          \n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# Show error in devtest\n",
    "show_errors(generate_errors(classifier, devtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 500 names, we have incorrectly classified 46 names. This is expected from the calculated accuracy rate of the classifier on the devtest dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix for Devtest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate prediction\n",
    "def generate_prediction(classifier, dataset): \n",
    "    \n",
    "    classification = [] \n",
    "\n",
    "    for (name, tag) in dataset:\n",
    "        guess = classifier.classify(get_features(name)) \n",
    "        classification.append((name,guess))\n",
    "            \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Brandice', 'female')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devtest1=generate_prediction(classifier, devtest)\n",
    "devtest1[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate confusion matrix and accuracy indicators\n",
    "def accuracy(actual, predicted):\n",
    "    test_result = []\n",
    "    gold_result = []\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        test_result.append(predicted[i][1])\n",
    "        gold_result.append(actual[i][1])\n",
    "    \n",
    "    CM = nltk.ConfusionMatrix(gold_result, test_result)\n",
    "    print(CM)\n",
    "\n",
    "    labels = ('female', 'male')\n",
    "\n",
    "    from collections import Counter\n",
    "    TP, FN, FP = Counter(), Counter(), Counter()\n",
    "    for i in labels:\n",
    "        for j in labels:\n",
    "            if i == j:\n",
    "                TP[i] += int(CM[i,j])\n",
    "            else:\n",
    "                FN[i] += int(CM[i,j])\n",
    "                FP[j] += int(CM[i,j])\n",
    "\n",
    "    print(\"label\\tprecision\\trecall\\tf_measure\")\n",
    "    for label in sorted(labels):\n",
    "        precision, recall = 0, 0\n",
    "        if TP[label] == 0:\n",
    "            f_measure = 0\n",
    "        else:\n",
    "            precision = float(TP[label]) / (TP[label]+FP[label])\n",
    "            recall = float(TP[label]) / (TP[label]+FN[label])\n",
    "            f_measure = float(2) * (precision * recall) / (precision + recall)\n",
    "        print(label+\"\\t\"+str(\"{:.5f}\".format(precision))+\"\\t\"+str(\"{:.5f}\".format(recall))+\"\\t\"+str(\"{:.5f}\".format(f_measure)))\n",
    "            \n",
    "\n",
    "#Ref: https://stackoverflow.com/questions/38541644/confusion-matrix-testing-sentiment-analysis-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |   f     |\n",
      "       |   e     |\n",
      "       |   m   m |\n",
      "       |   a   a |\n",
      "       |   l   l |\n",
      "       |   e   e |\n",
      "-------+---------+\n",
      "female |<288> 33 |\n",
      "  male |  13<166>|\n",
      "-------+---------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "label\tprecision\trecall\tf_measure\n",
      "female\t0.95681\t0.89720\t0.92605\n",
      "male\t0.83417\t0.92737\t0.87831\n"
     ]
    }
   ],
   "source": [
    "accuracy(devtest, devtest1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix for test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct=female   guess=male     name=Ambur                         \n",
      "correct=female   guess=male     name=Bab                           \n",
      "correct=female   guess=male     name=Barb                          \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Cher                          \n",
      "correct=female   guess=male     name=Chicky                        \n",
      "correct=female   guess=male     name=Cloris                        \n",
      "correct=female   guess=male     name=Ealasaid                      \n",
      "correct=female   guess=male     name=Eilis                         \n",
      "correct=female   guess=male     name=Gilligan                      \n",
      "correct=female   guess=male     name=Hannis                        \n",
      "correct=female   guess=male     name=Harriet                       \n",
      "correct=female   guess=male     name=Harriott                      \n",
      "correct=female   guess=male     name=Hester                        \n",
      "correct=female   guess=male     name=Hesther                       \n",
      "correct=female   guess=male     name=Inez                          \n",
      "correct=female   guess=male     name=Joy                           \n",
      "correct=female   guess=male     name=Kendre                        \n",
      "correct=female   guess=male     name=Mariam                        \n",
      "correct=female   guess=male     name=Meg                           \n",
      "correct=female   guess=male     name=Mercedes                      \n",
      "correct=female   guess=male     name=Mignon                        \n",
      "correct=female   guess=male     name=Nicol                         \n",
      "correct=female   guess=male     name=Ninon                         \n",
      "correct=female   guess=male     name=Olly                          \n",
      "correct=female   guess=male     name=Pearl                         \n",
      "correct=female   guess=male     name=Pepi                          \n",
      "correct=female   guess=male     name=Philis                        \n",
      "correct=female   guess=male     name=Rae                           \n",
      "correct=female   guess=male     name=Rhiamon                       \n",
      "correct=female   guess=male     name=Roz                           \n",
      "correct=female   guess=male     name=Steffie                       \n",
      "correct=female   guess=male     name=Umeko                         \n",
      "correct=female   guess=male     name=Vi                            \n",
      "correct=male     guess=female   name=Ambrosi                       \n",
      "correct=male     guess=female   name=Blaine                        \n",
      "correct=male     guess=female   name=Brian                         \n",
      "correct=male     guess=female   name=Case                          \n",
      "correct=male     guess=female   name=Clemente                      \n",
      "correct=male     guess=female   name=Donn                          \n",
      "correct=male     guess=female   name=Enrique                       \n",
      "correct=male     guess=female   name=Ezra                          \n",
      "correct=male     guess=female   name=Fidel                         \n",
      "correct=male     guess=female   name=Galen                         \n",
      "correct=male     guess=female   name=Hezekiah                      \n",
      "correct=male     guess=female   name=Josiah                        \n",
      "correct=male     guess=female   name=Larry                         \n",
      "correct=male     guess=female   name=Louie                         \n",
      "correct=male     guess=female   name=Martainn                      \n",
      "correct=male     guess=female   name=Obie                          \n",
      "correct=male     guess=female   name=Percy                         \n",
      "correct=male     guess=female   name=Thane                         \n",
      "correct=male     guess=female   name=Thayne                        \n",
      "correct=male     guess=female   name=Winn                          \n",
      "54\n"
     ]
    }
   ],
   "source": [
    "#show errors\n",
    "show_errors(generate_errors(classifier, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |   f     |\n",
      "       |   e     |\n",
      "       |   m   m |\n",
      "       |   a   a |\n",
      "       |   l   l |\n",
      "       |   e   e |\n",
      "-------+---------+\n",
      "female |<284> 34 |\n",
      "  male |  20<162>|\n",
      "-------+---------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "label\tprecision\trecall\tf_measure\n",
      "female\t0.93421\t0.89308\t0.91318\n",
      "male\t0.82653\t0.89011\t0.85714\n"
     ]
    }
   ],
   "source": [
    "test1 = generate_prediction(classifier, test)\n",
    "accuracy(test, test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the performance on the test set compare to the performance on the dev-test set? Is this what you would expect?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the features \n",
    "\n",
    "def summary(nruns, feature_function): #nruns=no of runs, feature_function= feature to be used\n",
    "    accuracy_df = {\n",
    "        \"classifier\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_accuracy\": [],\n",
    "        \"devtest_accuracy\": [],\n",
    "        \"devtest_errors\": []\n",
    "    }\n",
    "    for i in range(nruns):\n",
    "        random.shuffle(final_names)\n",
    "        accuracy_test = final_names[:500]\n",
    "        accuracy_devtest = final_names[500:1000]\n",
    "        accuracy_train = final_names[1000:]\n",
    "        \n",
    "            \n",
    "        accuracy_trainset = [(feature_function(n), g) for (n,g) in accuracy_train]\n",
    "        accuracy_devtestset = [(feature_function(n), g) for (n,g) in accuracy_devtest]\n",
    "        accuracy_testset = [(feature_function(n), g) for (n,g) in accuracy_test]\n",
    "        \n",
    "        accuracy_classifier = nltk.NaiveBayesClassifier.train(accuracy_trainset)\n",
    "        accuracy_df[\"classifier\"].append(accuracy_classifier)\n",
    "        accuracy_df[\"train_accuracy\"].append(nltk.classify.accuracy(accuracy_classifier, accuracy_trainset))\n",
    "        accuracy_df[\"test_accuracy\"].append(nltk.classify.accuracy(accuracy_classifier, accuracy_testset))\n",
    "        accuracy_df[\"devtest_accuracy\"].append(nltk.classify.accuracy(accuracy_classifier, accuracy_devtestset))\n",
    "        \n",
    "        accuracy_errors = []\n",
    "        for (name, tag) in accuracy_devtest:\n",
    "            accuracy_guess = accuracy_classifier.classify(feature_function(name))\n",
    "            if accuracy_guess != tag:\n",
    "                accuracy_errors.append( (tag, accuracy_guess, name) )\n",
    "        accuracy_df[\"devtest_errors\"].append(accuracy_errors)\n",
    "        \n",
    "    accuracy_df = pd.DataFrame.from_dict(accuracy_df)\n",
    "    return(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>devtest_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.945332</td>\n",
       "      <td>0.894740</td>\n",
       "      <td>0.893440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.013953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.941423</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.864000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.944319</td>\n",
       "      <td>0.886000</td>\n",
       "      <td>0.884000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.945285</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.946411</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.949147</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.922000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_accuracy  test_accuracy  devtest_accuracy\n",
       "count      100.000000     100.000000        100.000000\n",
       "mean         0.945332       0.894740          0.893440\n",
       "std          0.001448       0.012594          0.013953\n",
       "min          0.941423       0.862000          0.864000\n",
       "25%          0.944319       0.886000          0.884000\n",
       "50%          0.945285       0.896000          0.892000\n",
       "75%          0.946411       0.902000          0.904000\n",
       "max          0.949147       0.920000          0.922000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summary(100, get_features)\n",
    "summary.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?**\n",
    "\n",
    "We would expect that the accuracy indicators for devtest and test to be close to each other, as we have shuffled the datasets. In the above table, we have run the feature function we generated 100 times, every time with the final_names shuffled. We see accuracy go down from 94.5% for train to 89% for devtest and test. The summary measures for test_accuracy and devtest_accuracy are very close to each other, confirming our expectation.\n",
    "\n",
    "Let us now test this on a different dataset, amuch bigger one. The dataset can be found at https://data.world/len/us-first-names-database and containd 32,952 names. The csv has been uploaded at https://github.com/ShovanBiswas/DATA620/blob/master/Week09/test2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv('https://raw.githubusercontent.com/ShovanBiswas/DATA620/master/Week09/test2.csv')\n",
    "test2 = test2.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is\n",
      "0.8606457878125758\n"
     ]
    }
   ],
   "source": [
    "test2_set = [(get_features(n), g) for (n,g) in test2]\n",
    "classifier = nltk.NaiveBayesClassifier.train(test2_set) \n",
    "print('Accuracy is')\n",
    "print(nltk.classify.accuracy(classifier, test2_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict for the test data\n",
    "test2_predict = generate_prediction(classifier, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |     f       |\n",
      "       |     e       |\n",
      "       |     m     m |\n",
      "       |     a     a |\n",
      "       |     l     l |\n",
      "       |     e     e |\n",
      "-------+-------------+\n",
      "female |<16363> 2630 |\n",
      "  male |  1962<11997>|\n",
      "-------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "label\tprecision\trecall\tf_measure\n",
      "female\t0.89293\t0.86153\t0.87695\n",
      "male\t0.82020\t0.85945\t0.83936\n"
     ]
    }
   ],
   "source": [
    "accuracy(test2, test2_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an 86% accuracy, which is lower than our original test dataset at 89%, but does not differ significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
